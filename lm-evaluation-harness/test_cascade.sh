
# models=(
#     "meta-llama/Llama-3.2-3B-Instruct",
#     "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_Llama-3.2-3B-instruct_20k_math-verify-skip_cascade_ds3/20251002-220228",
#     "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_Llama-3.2-3B-instruct_20k_sft_ds3/20251002-184518",
#     "Qwen/Qwen2.5-1.5B-instruct",
#     "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-1.5b-instruct_20k_math-verify-skip_cascade_ds3/20251002-073227",
#     "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-1.5b-instruct_20k_sft_ds3/20251001-004541",
#     "Qwen/Qwen2.5-3B",
#     "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-3b_20k_math-verify-skip_cascade_ds3/20251003-044546",
#     "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-3b_20k_sft_ds3/20251003-012549",
#     "Qwen/Qwen2.5-3B-instruct",
#     "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-3b-instruct_20k_math-verify-skip_cascade_ds3/20251002-091353",
#     "Qwen/Qwen2.5-7B-instruct",
#     "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-7b-instruct_20k_math-verify-skip_cascade_ds3/20251002-120950",
#     "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-7b-instruct_20k_sft_ds3/20251001-032444"
# )

# models=("meta-llama/Llama-3.2-3B-Instruct")
# models=("Qwen/Qwen2.5-1.5B-Instruct")
# models=("Qwen/Qwen2.5-3B" "Qwen/Qwen2.5-7B-Instruct")
# models=("Qwen/Qwen2.5-3B-Instruct")
# models=("/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_Llama-3.2-3B-instruct_20k_math-verify-skip_cascade_ds3/20251002-220228" "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_Llama-3.2-3B-instruct_20k_sft_ds3/20251002-184518")
# models=("/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-1.5b-instruct_20k_math-verify-skip_cascade_ds3/20251002-073227" "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-1.5b-instruct_20k_sft_ds3/20251001-004541" "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-3b_20k_math-verify-skip_cascade_ds3/20251003-044546" "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-3b_20k_sft_ds3/20251003-012549" "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-3b-instruct_20k_math-verify-skip_cascade_ds3/20251002-091353" "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-7b-instruct_20k_math-verify-skip_cascade_ds3/20251002-120950" "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-7b-instruct_20k_sft_ds3/20251001-032444")

# models=("/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-1.5b_20k_sft_ds3/20251004-203803" "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-1.5b_20k_math-verify_cascade_ds3/20251004-224209")

models=("/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_Llama-3.2-3B-instruct_20k_cascade-filter-top2500_ds3/20251005-085514" "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-1.5b_20k_cascade-filter-top2500_ds3/20251005-105438" "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-1.5b-instruct_20k_cascade-filter-top2500_ds3/20251005-094109" "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-3b_20k_cascade-filter-top2500_ds3/20251005-120807" "/home/aiscuser/CascadeDistill/saves/deepseek_qwen2.5-7b-instruct_qwen2.5-1.5b-instruct_20k/deepseek_qwen2.5-3b-instruct_20k_cascade-filter-top2500_ds3/20251005-100809")

tasks=("AIME" "AMC" "Olympiad" "hendrycks_math_500" "gsm8k_cot_zeroshot" "hendrycks_math")

max_model_tokens=16000
max_gen_tokens=16000
model_args="tensor_parallel_size=1,data_parallel_size=8,gpu_memory_utilization=0.8,max_model_len=$max_model_tokens,dtype=bfloat16"
output_path="Cascade_results"
batch_size="auto"

for task in "${tasks[@]}"; do
    for model in "${models[@]}"; do
        echo "Running lm_eval with model: $model, task: $task"
        lm_eval --model vllm \
            --model_args pretrained="$model",$model_args \
            --gen_kwargs do_sample=false,temperature=0,max_gen_toks=$max_gen_tokens \
            --tasks "$task" \
            --batch_size "$batch_size" \
            --log_samples \
            --trust_remote_code \
            --output_path "$output_path" \
            --apply_chat_template \


        SANTIZED_MODEL_SAVE_LABEL=$(echo ${model} | sed 's/\//__/g')
        echo ${SANTIZED_MODEL_SAVE_LABEL}
        if [ "$task" != "gsm8k_cot_zeroshot" ]; then
            python math_metric_llm_eval_general.py --directory_path ${output_path}/${SANTIZED_MODEL_SAVE_LABEL} --task ${task}
        elif [ "$task" == "gsm8k_cot_zeroshot" ]; then
            python math_metric_gsm8k.py --directory_path ${output_path}/${SANTIZED_MODEL_SAVE_LABEL} 
        fi


    done
done
